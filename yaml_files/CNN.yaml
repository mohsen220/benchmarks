seed: 1234
__set_torchseed: !apply:torch.manual_seed [!ref <seed>]

# DIRECTORIES
data_folder: !PLACEHOLDER
cached_data_folder: !PLACEHOLDER
output_folder: !PLACEHOLDER

# DATASET HPARS
dataset: !new:moabb.datasets.BNCI2014001
save_prepared_dataset: True
data_iterator_name: !PLACEHOLDER
target_subject_idx: !PLACEHOLDER
target_session_idx: !PLACEHOLDER
events_to_load: null
original_sample_rate: 250
sample_rate: 125
fmin: 0.13  # @orion_step1: --fmin~"uniform(0.1, 5, precision=2)"
fmax: 46.0  # @orion_step1: --fmax~"uniform(20.0, 50.0, precision=3)"
n_classes: 4
tmin: 0.
tmax: 4.0  # @orion_step1: --tmax~"uniform(1.0, 4.0, precision=2)"
n_steps_channel_selection: 2  # @orion_step1: --n_steps_channel_selection~"uniform(1, 3,discrete=True)"
T: !apply:math.ceil
    - !ref <sample_rate> * (<tmax> - <tmin>)
C: 22
test_with: 'last'
test_key: "acc"

# METRICS
f1: !name:sklearn.metrics.f1_score
    average: 'macro'
acc: !name:sklearn.metrics.balanced_accuracy_score
cm: !name:sklearn.metrics.confusion_matrix
metrics:
    f1: !ref <f1>
    acc: !ref <acc>
    cm: !ref <cm>

# TRAINING HPARS
n_train_examples: 100
avg_models: 10  # @orion_step2: --avg_models~"uniform(1, 15,discrete=True)"
number_of_epochs: 862  # @orion_step1: --number_of_epochs~"uniform(250, 1000, discrete=True)"
lr: 0.0001  # @orion_step1: --lr~"choices([0.01, 0.005, 0.001, 0.0005, 0.0001])"
max_lr: !ref <lr>
base_lr: 0.00000001
step_size_multiplier: 5
step_size: !apply:round
    - !ref <step_size_multiplier> * <n_train_examples> / <batch_size>
lr_annealing: !new:speechbrain.nnet.schedulers.CyclicLRScheduler
    base_lr: !ref <base_lr>
    max_lr: !ref <max_lr>
    step_size: !ref <step_size>
label_smoothing: 0.0  # @orion_step2: --label_smoothing~"uniform(0.0, 0.1)"
loss: !name:speechbrain.nnet.losses.nll_loss
    label_smoothing: !ref <label_smoothing>
optimizer: !name:torch.optim.Adam
    lr: !ref <lr>
epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <number_of_epochs>
batch_size_exponent: 4  # @orion_step1: --batch_size_exponent~"uniform(4, 6,discrete=True)"
batch_size: !ref 2 ** <batch_size_exponent>
valid_ratio: 0.2

# DATA AUGMENTATION
max_num_segments: 3  # @orion_step2: --max_num_segments~"uniform(2, 6, discrete=True)"
cutcat: !new:speechbrain.augment.time_domain.CutCat
    min_num_segments: 2
    max_num_segments: !ref <max_num_segments>
amp_delta: 0.01742  # @orion_step2: --amp_delta~"uniform(0.0, 0.5)"
rand_amp: !new:speechbrain.augment.time_domain.RandAmp
    amp_low: !ref 1 - <amp_delta>
    amp_high: !ref 1 + <amp_delta>
shift_delta_: 1
shift_delta: !ref 1e-2 * <shift_delta_>  # @orion_step2: --shift_delta_~"uniform(0, 25, discrete=True)"
min_shift: !apply:math.floor
    - !ref 0 - <sample_rate> * <shift_delta>
max_shift: !apply:math.floor
    - !ref 0 + <sample_rate> * <shift_delta>
time_shift: !new:speechbrain.augment.freq_domain.RandomShift
    min_shift: !ref <min_shift>
    max_shift: !ref <max_shift>
    dim: 1
snr_white_low: 15.0  # @orion_step2: --snr_white_low~"uniform(0.0, 15, precision=2)"
snr_white_delta: 19.1
snr_white_high: !ref <snr_white_low> + <snr_white_delta>
add_noise_white: !new:speechbrain.augment.time_domain.AddNoise
    snr_low: !ref <snr_white_low>
    snr_high: !ref <snr_white_high>
repeat_augment: 1
augment: !new:speechbrain.augment.augmenter.Augmenter
    parallel_augment: True
    concat_original: True
    parallel_augment_fixed_bs: True
    repeat_augment: !ref <repeat_augment>
    shuffle_augmentations: True
    min_augmentations: 4
    max_augmentations: 4
    augmentations: [
        !ref <cutcat>,
        !ref <rand_amp>,
        !ref <time_shift>,
        !ref <add_noise_white>]

# DATA NORMALIZATION
dims_to_normalize: 1
normalize: !name:speechbrain.processing.signal_processing.mean_std_norm
    dims: !ref <dims_to_normalize>

# MODEL 
input_shape: [null, !ref <T>, !ref <C>, null]
model: !new:models.CNN.CNN
    input_shape: !ref <input_shape>
    num_classes: !ref <n_classes>
